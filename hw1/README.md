# 第一次作业

网络爬虫：计算中英文本的熵

## 1. 任务描述

分别收集尽量多的英语和汉语文本，编写程序计算这些文本中英语字母和汉字的熵，对比本章课件第18页上表中给出的结果。然后逐步扩大文本规模，如每次增加固定的数量，如2M/5M等，重新计算文本规模扩大之后的熵，分析多次增加之后熵的变化情况。

要求：

1. 利用爬虫工具从互联网上收集样本，并对样本进行处理，如清洗乱码等；

2. 设计算法并编程实现在收集样本上字母/汉字的概率和熵的计算；

3. 当改变样本规模时重新计算字母/汉字的概率和熵, 并对比计算结果；

4. 完成一份技术报告，在报告中写明利用什么爬虫工具从哪些网站上收集的样本，如何进行的样本清洗，清洗后样本的规模，在不同样本规模下计算的结果等。(注意：实验分析有较大的伸缩空间)

## 如何运行

在终端中输入以下命令

```
bash run.sh
```

## 文件说明

- `crawler.py`：爬虫代码
- `analyze.py`：熵计算代码
- `run.sh`：运行脚本
- `report/`：实验报告所在目录
- `seed_CH.txt`：中文种子文本
- `seed_EN.txt`：英文种子文本
- `result_CH.txt`：中文文本数据
- `result_EN.txt`：英文文本数据
- `analysis_CH/`：中文熵计算结果
- `analysis_EN/`：英文熵计算结果